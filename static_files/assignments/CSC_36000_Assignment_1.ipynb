{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZs2oqB5poqM"
      },
      "source": [
        "Name:  **Your name here**  \n",
        "ID:  **Your student ID num here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVTaT35yVpmP"
      },
      "source": [
        "## Academic Integrity Statement\n",
        "\n",
        " I, **Write your Student Name here replacing this comment**, having Student ID **Write your Student ID here replacing this comment**, fully support this courses CSC3600â€™s AI policy and the City College of New York's policy on Academic Honesty, which states the following in the Syllabus Document under GenAI policy and University policy https://saptab.github.io/modern-distributed-computing-with-AI-Agents/static_files/Syllabus.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs5E7dDQpoqO"
      },
      "source": [
        "# Homework 1:  Metrics and MultiProcessing (100 points) (Mandatory for all Students) (Additional 20 points bonus credits, optional for any Student)\n",
        "Upload your notebook (a file with extension \".ipynb\") to BrightSpace. Make sure to run each unit test cell before uploading to make sure your correct result is visible. Use Google Colaboratory for a free platform to test your code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvsg11TDQ74m"
      },
      "source": [
        "You will be answering coding questions on the metrics for distributed systems and multiprocessing taught in class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOUXMZo7RD7R"
      },
      "source": [
        "You will also answer unit tests to make sure your code works with example use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1h-j03nRQXI"
      },
      "source": [
        "An example usecase is as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBRcK5Q0Jm"
      },
      "outputs": [],
      "source": [
        "assert abs(predicted_value - Expected_value) < 1e-9, f\"Test Failed: Expected {Expected_value}, but got {predicted_value}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT7RjM8wRdCE"
      },
      "source": [
        "This means that you see how close the predicted (or computed) value is to the expected (groundtruth) value in your test and you share whether your test failed or not, using the assert statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzy3QBy8Rt2b"
      },
      "source": [
        "Read about the assert statement for unit tests here\n",
        "\n",
        "https://docs.pytest.org/en/stable/how-to/assert.html\n",
        "\n",
        "https://docs.python.org/3/reference/simple_stmts.html#grammar-token-python-grammar-assert_stmt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxVOw4-TaVzt"
      },
      "source": [
        "Write your code (and your unit test code) in the indicated comment. You can use functions or classes as you deem fit.\n",
        "\n",
        "Follow the descriptions and hints in the comments below\n",
        "\n",
        "Remove the pass coding statement once you have replaced your the \"#YOUR CODE\" comment with your code and have your own return statements as appropriate\n",
        "\n",
        "Do not change any existing code already written in this Notebook or your code will not work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJrENujkpoqO"
      },
      "source": [
        "## Problem 1:  Performance Metrics (50 points)\n",
        "\n",
        "In class, we covered four metrics to assess the performance of a system: Accuracy, Precision, Recall, and F-measure. In this problem we will code each one by hand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tkCHRxwtOPh"
      },
      "source": [
        "### Problem 1(a): Accuracy (10 points)\n",
        "\n",
        "Accuracy measures the proportion of total predictions that were correct. It is one of the most common evaluation metrics.\n",
        "\n",
        "The formula for $\\text{Accuracy}$ is given as:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\n",
        "\\text{True Positives}+\\text{TrueÂ Negatives}\n",
        "}\n",
        "{\n",
        "  {\\text{FalseÂ Positives}+\\text{FalseÂ Negatives}} + \\text{TrueÂ Positives}+\\text{TrueÂ Negatives}\n",
        "}\n",
        "â€‹$$\n",
        "\n",
        "In this cell, implement a Python function that calculates Accuracy. (6 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blPdr5xHubkz"
      },
      "outputs": [],
      "source": [
        "def accuracy(tp, tn, fp, fn):\n",
        "  \"\"\"\n",
        "  Calculates the accuracy of a classification model.\n",
        "\n",
        "  Args:\n",
        "    tp: An integer representing the number of true positives.\n",
        "    tn: An integer representing the number of true negatives.\n",
        "    fp: An integer representing the number of false positives.\n",
        "    fn: An integer representing the number of false negatives.\n",
        "\n",
        "  Returns:\n",
        "    A float representing the accuracy score.\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QckXxu4CW394"
      },
      "source": [
        "### Unit Test\n",
        "Write your unit test here to show that your solution is correct (4 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1dJ7KDAW-RL"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "tp_test = 90\n",
        "tn_test = 50\n",
        "fp_test = 10\n",
        "fn_test = 5\n",
        "\n",
        "expected_accuracy = 0.9032258065\n",
        "calculated_accuracy = accuracy(tp_test, tn_test, fp_test, fn_test)\n",
        "\n",
        "# YOUR UNIT TEST CODE HERE\n",
        "\n",
        "print(\"Accuracy test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3NwJ2DWkRn"
      },
      "source": [
        "### Problem 1(b): Precision (10 points)\n",
        "\n",
        "Precision answers the question: \"Of all the predictions that were positive, how many were actually correct?\" It measures exactness. A low precision indicates a high number of false positives.\n",
        "\n",
        "The formula for $\\text{Precision}$ is given as:\n",
        "\n",
        "$$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$$\n",
        "\n",
        "In this cell, implement a Python function that calculates Precision. (6 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvyMfU3RWxcM"
      },
      "outputs": [],
      "source": [
        "def precision(tp, fp):\n",
        "  \"\"\"\n",
        "  Calculates the precision of a classification model.\n",
        "\n",
        "  Args:\n",
        "    tp: An integer representing the number of true positives.\n",
        "    fp: An integer representing the number of false positives.\n",
        "\n",
        "  Returns:\n",
        "    A float representing the precision score.\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo5_5mtcpoqO"
      },
      "source": [
        "### Unit Test\n",
        "Write your unit test here to show that your solution is correct (4 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PCabwB7XQSq"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "tp_test = 90\n",
        "fp_test = 10\n",
        "\n",
        "expected_precision = 0.9\n",
        "calculated_precision = precision(tp_test, fp_test)\n",
        "\n",
        "# YOUR UNIT TEST CODE HERE\n",
        "\n",
        "print(\"Precision test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-uWH3TUX-yC"
      },
      "source": [
        "### Problem 1(c): Recall (Sensitivity) (10 points)\n",
        "\n",
        "Recall answers the question: \"Of all the actual positive cases, how many did the model correctly identify?\" It measures a classifier's completeness. A low recall indicates a high number of false negatives.\n",
        "\n",
        "The formula for $\\text{Recall}$ is given as:\n",
        "\n",
        "$$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$$\n",
        "\n",
        "In this cell, implement a Python function that calculates Recall. (6 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu2p7lLLYL_B"
      },
      "outputs": [],
      "source": [
        "def recall(tp, fn):\n",
        "  \"\"\"\n",
        "  Calculates the recall of a classification model.\n",
        "\n",
        "  Args:\n",
        "    tp: An integer representing the number of true positives.\n",
        "    fn: An integer representing the number of false negatives.\n",
        "\n",
        "  Returns:\n",
        "    A float representing the recall score.\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKNMoSD7YOma"
      },
      "source": [
        "### Unit Test\n",
        "Write your unit test here to show that your solution is correct (4 of these 10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Va0GklSUpoqQ",
        "outputId": "b0084364-8525-4de1-e4e4-aa2c0574e891"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'recall' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-906840312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexpected_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcalculated_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# YOUR UNIT TEST CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recall' is not defined"
          ]
        }
      ],
      "source": [
        "# Test case\n",
        "tp_test = 90\n",
        "fn_test = 5\n",
        "\n",
        "expected_recall = 0.9473684211\n",
        "calculated_recall = recall(tp_test, fn_test)\n",
        "\n",
        "# YOUR UNIT TEST CODE HERE\n",
        "\n",
        "print(\"Recall test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8xP-Pv9YTAM"
      },
      "source": [
        "### Problem 1(d): F-Measure (F1-Score) (20 points)\n",
        "\n",
        "The F-measure, or F1-score, is the **harmonic mean** of precision and recall. It provides a single score that balances both metrics, which is particularly useful when you have an uneven class distribution. An F1-score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
        "\n",
        "The formula for the $\\text{F1-Score}$ is given as:\n",
        "\n",
        "$$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "In this cell, implement a Python function that calculates the F-Measure. Use the $\\text{Precision}$ and $\\text{Recall}$ functions you created in 1(b) and 1(c). (15 of these 20 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxQf65l6YoGu"
      },
      "outputs": [],
      "source": [
        "def f_measure(tp, fp, fn):\n",
        "  \"\"\"\n",
        "  Calculates the F1-score (f-measure) of a classification model.\n",
        "  This function should use your previously defined precision() and recall() functions.\n",
        "\n",
        "  Args:\n",
        "    tp: An integer representing the number of true positives.\n",
        "    fp: An integer representing the number of false positives.\n",
        "    fn: An integer representing the number of false negatives.\n",
        "\n",
        "  Returns:\n",
        "    A float representing the F1-score.\n",
        "  \"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  # Hint: Call your precision() and recall() functions\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rUNZeX5aJwH"
      },
      "source": [
        "### Unit Test\n",
        "Write your unit test here to show that your solution is correct (5 of these 20 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J9i2T1jaLFx"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "tp_test = 90\n",
        "fp_test = 10\n",
        "fn_test = 5\n",
        "\n",
        "# Calculate precision and recall using the student's functions\n",
        "\n",
        "expected_f_measure = 0.9230769231\n",
        "calculated_f_measure = f_measure(tp_test, fp_test, fn_test)\n",
        "\n",
        "# YOUR UNIT TEST CODE HERE\n",
        "\n",
        "print(\"F-Measure test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La1sxxijbbb5"
      },
      "source": [
        "## Problem 2: Introduction to Multiprocessing (50 points)\n",
        "\n",
        "**Multiprocessing** is a Python package that allows you to spawn processes, enabling your programs to fully leverage multiple processors on a given machine. Unlike the `threading` module, it uses separate memory spaces for each process. This makes it ideal for CPU-bound tasks.\n",
        "\n",
        "In this problem, we'll explore the fundamentals of creating and managing processes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP_svCAybhbV"
      },
      "source": [
        "### Problem 2(a): Creating and Running a Single Process (20 points)\n",
        "\n",
        "The basic way to create a process is to instantiate a `multiprocessing.Process` object. You give it a target function to execute and arguments for that function. Once you `start()` the process, it runs in its own memory space.\n",
        "\n",
        "To get results back from a process, we need to use a communication tool like a `Queue`.\n",
        "\n",
        "In this cell, implement the `run_single_process` function. It should:\n",
        "1.  Define a simple worker function `square_number` that takes a number and a queue, calculates the square of the number, and `put`s the result into the queue.\n",
        "2.  Create a `multiprocessing.Process` that targets your `square_number` function.\n",
        "3.  Start the process and then wait for it to complete using `.join()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGRKJv4YbxqR"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def run_single_process(number, result_queue):\n",
        "  \"\"\"\n",
        "  Runs a single process to square a number and puts the result in a queue.\n",
        "\n",
        "  Args:\n",
        "    number: The number to square.\n",
        "    result_queue: A multiprocessing.Queue to store the result.\n",
        "  \"\"\"\n",
        "\n",
        "  def square_number(n, q):\n",
        "    \"\"\"Worker function: squares a number and puts it into the queue.\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    pass\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  # 1. Create a Process object.\n",
        "  # 2. Start the process.\n",
        "  # 3. Wait for the process to finish.\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnmxfEGhcPCP"
      },
      "source": [
        "### Unit Test\n",
        "Run this cell to see if your solution is correct! Do not modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O64pxz-bcTLn"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "q = multiprocessing.Queue()\n",
        "test_number = 8\n",
        "run_single_process(test_number, q)\n",
        "\n",
        "# Check if the queue is not empty and contains the correct result\n",
        "assert not q.empty(), \"Test Failed: The result queue is empty.\"\n",
        "result = q.get()\n",
        "expected_result = test_number ** 2\n",
        "assert result == expected_result, f\"Test Failed: Expected {expected_result}, but got {result}.\"\n",
        "\n",
        "print(\"Single process test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGIdBbFTcXZk"
      },
      "source": [
        "### Problem 2(b): Running Multiple Processes in Parallel (30 points)\n",
        "\n",
        "The real power of multiprocessing comes from running many tasks at once. The standard pattern is:\n",
        "1.  Create a list of `Process` objects.\n",
        "2.  Loop through the list and `start()` each one.\n",
        "3.  Loop through the list again and `join()` each one to wait for them all to finish.\n",
        "\n",
        "In this cell, implement the `run_multiple_processes` function to square all numbers in a list, each in its own process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKv1WbfNdHHK"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "def run_multiple_processes(numbers, result_queue):\n",
        "  \"\"\"\n",
        "  Runs multiple processes in parallel to square a list of numbers.\n",
        "\n",
        "  Args:\n",
        "    numbers: A list of numbers to square.\n",
        "    result_queue: A multiprocessing.Queue to store the results.\n",
        "  \"\"\"\n",
        "  # You'll need the same worker function as before\n",
        "  def square_number(n, q):\n",
        "    # YOUR CODE HERE\n",
        "    pass\n",
        "\n",
        "  processes = []\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  # 1. Create a process for each number and add it to the 'processes' list.\n",
        "\n",
        "  # 2. Start all processes.\n",
        "\n",
        "  # 3. Wait for all processes to finish.\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaAHhzyQdWQx"
      },
      "source": [
        "### Unit Test\n",
        "Run this cell to see if your solution is correct! Do not modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KATooUcdh1t"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "q = multiprocessing.Queue()\n",
        "test_numbers = [2, 3, 5, 7, 11]\n",
        "run_multiple_processes(test_numbers, q)\n",
        "\n",
        "# Retrieve results from the queue\n",
        "results = []\n",
        "while not q.empty():\n",
        "  results.append(q.get())\n",
        "\n",
        "expected_results = [n*n for n in test_numbers]\n",
        "\n",
        "# The order of results isn't guaranteed, so we sort them to compare\n",
        "results.sort()\n",
        "expected_results.sort()\n",
        "\n",
        "assert results == expected_results, f\"Test Failed: Expected {expected_results}, but got {results}.\"\n",
        "\n",
        "print(\"Multiple processes test passed! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6BbS2pAdj3B"
      },
      "source": [
        "## Extra Bonus Credit: Using a Process Pool for Efficiency (20 points additionally)\n",
        "\n",
        "Manually creating, starting, and joining processes can be tedious. The `multiprocessing.Pool` object provides a much more convenient way to manage a pool of worker processes. A common method is `pool.map()`, which maps a function onto a list of inputs, distributing the work among the available processes and collecting the results for you.\n",
        "\n",
        "In this cell, implement `run_with_pool` to use a `Pool` to square a list of numbers. Note that `pool.map` handles returning results, so you no longer need a `Queue`. (15 out of these 20 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mWQM6upd87G"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square_number_simple(n):\n",
        "  \"\"\"A simple worker function that just returns the result.\"\"\"\n",
        "  # YOUR CODE HERE\n",
        "  pass\n",
        "\n",
        "def run_with_pool(numbers):\n",
        "  \"\"\"\n",
        "  Uses a multiprocessing.Pool to square a list of numbers.\n",
        "\n",
        "  Args:\n",
        "    numbers: A list of numbers to square.\n",
        "\n",
        "  Returns:\n",
        "    A list of the squared numbers.\n",
        "  \"\"\"\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  # Hint: Use a 'with' statement to manage the pool's lifecycle.\n",
        "  # 'multiprocessing.cpu_count()' can be useful to determine pool size.\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om3dgrXueER6"
      },
      "source": [
        "### Unit Test\n",
        "Write an Unit test to show that your solution is correct. (5 of these 20 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipxvQ75ueTH-"
      },
      "outputs": [],
      "source": [
        "# Test case\n",
        "test_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "results = run_with_pool(test_numbers)\n",
        "\n",
        "expected_results = [n*n for n in test_numbers]\n",
        "\n",
        "# pool.map preserves the order of the results\n",
        "\n",
        "# YOUR UNIT TEST CODE HERE\n",
        "\n",
        "print(\"Process Pool test passed! ðŸŽ‰\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
